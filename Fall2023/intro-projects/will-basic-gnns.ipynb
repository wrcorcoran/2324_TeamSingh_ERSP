{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from dgl.data import CoraGraphDataset, CiteseerGraphDataset, PubmedGraphDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "# Graph Convolutional Network\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, g, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()                         # initial the graph convolutional network parent class\n",
    "        self.conv1 = dgl.nn.GraphConv(in_feats, h_feats)    # in feats: size of input feature vector, h feats: size of output\n",
    "        self.conv2 = dgl.nn.GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "\n",
    "def train_and_save_embeddings_and_edges(dataset, dataset_name):\n",
    "    g = dataset[0]\n",
    "    features = g.ndata['feat']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "\n",
    "    graph_features = g.ndata['feat'].numpy()\n",
    "    graph_labels = g.ndata['label'].numpy()\n",
    "    np.save(f'{dataset_name}_features.npy', graph_features)\n",
    "    np.save(f'{dataset_name}_labels.npy', graph_labels)\n",
    "\n",
    "    in_feats = features.shape[1]\n",
    "    h_feats = 64\n",
    "    num_classes = dataset.num_classes\n",
    "    model = GCN(g, in_feats, h_feats, num_classes)\n",
    "\n",
    "    # Train the model\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    for epoch in range(200):\n",
    "        model.train()\n",
    "        logits = model(g, features)\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "        print(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Extract and save the embeddings\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(g, features)\n",
    "    print(embeddings.shape)\n",
    "    np.save(f'{dataset_name}_embeddings.npy', embeddings.detach().numpy())\n",
    "\n",
    "\n",
    "    edge_index = g.edges()\n",
    "    np.save(f'{dataset_name}_edge_index.npy', np.vstack((edge_index[0].numpy(), edge_index[1].numpy())))\n",
    "\n",
    "# Load the datasets\n",
    "cora_dataset = CoraGraphDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9455, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8994, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8693, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8372, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7636, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7215, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6772, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6303, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5805, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5283, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4739, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4174, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3591, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2993, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2382, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1762, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1137, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0511, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9889, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9273, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8667, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8075, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7502, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6949, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6421, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5919, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5446, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4588, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3849, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3522, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2947, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2697, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2468, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2070, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1898, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1742, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1600, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1471, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1355, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1249, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1065, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0986, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0914, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0849, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0789, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0735, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0686, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0641, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0601, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0563, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0529, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0498, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0470, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0443, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0419, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0397, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0377, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0359, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0341, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0326, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0311, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0297, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0285, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0273, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0262, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0243, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0123, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0104, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0083, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0082, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0080, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0079, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0077, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0075, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0074, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0073, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0072, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0071, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0070, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0069, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0068, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0067, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0066, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0066, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0065, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0064, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0063, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0062, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0062, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0060, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0059, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0059, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0058, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0057, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0057, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0056, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0055, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0055, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0054, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0054, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0053, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0052, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0052, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0051, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0051, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0050, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0050, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0049, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0049, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0047, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0047, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0045, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0045, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0044, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0044, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0043, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0043, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0043, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0042, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0042, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([2708, 7])\n"
     ]
    }
   ],
   "source": [
    "train_and_save_embeddings_and_edges(cora_dataset, 'cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = np.load('cora_embeddings.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_for_faiss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
